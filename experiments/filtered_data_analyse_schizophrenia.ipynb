{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33d8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../core/\")\n",
    "from experiments import run\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797311b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_package =r'C:\\Users\\User\\Documents\\Skolkovo\\projects\\Sharjah\\Schizophrenia Excel files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18712336",
   "metadata": {},
   "outputs": [],
   "source": [
    "files =list(Path(data_package).iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2b8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(filepath):\n",
    "    data=pd.read_excel(filepath)\n",
    "    data =data.T\n",
    "    data =data.reset_index()\n",
    "    data.columns = data.iloc[0]\n",
    "    data =data[2:]\n",
    "    data['target'] =data['NAME'].apply(lambda x: x.split(\"_\")[0])\n",
    "    data['target']= data['target'].map({'Schizo1':1, 'Ctrl1': 0})\n",
    "    print(data.select_dtypes(include=['object']))\n",
    "    y =data['target']\n",
    "    X=data.iloc[:, 1:-1].astype(float)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db6519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                NAME      HTR4      HTR6      HTR7   LURAP1L        BBX  \\\n",
      "2   Schizo1_GSM677118  5.727914   3.49068  3.680865  2.199321  10.761437   \n",
      "3   Schizo1_GSM677119  5.724901   3.49068  3.024656  2.199321   10.63498   \n",
      "4   Schizo1_GSM677120  6.239469   3.49068  3.505588  2.199321  10.483729   \n",
      "5   Schizo1_GSM677121  5.711125   3.48934  3.267655  2.199321  10.919826   \n",
      "6   Schizo1_GSM677122  5.100501  3.564864  3.024656  2.199321  10.549424   \n",
      "..                ...       ...       ...       ...       ...        ...   \n",
      "69    Ctrl1_GSM677178  5.681799   3.49068  3.024656   2.20113  11.646984   \n",
      "70    Ctrl1_GSM677179  5.730127   3.48934  3.024656  2.199321  11.536132   \n",
      "71    Ctrl1_GSM677180  5.681799   3.49068  3.024656  2.232711   11.53018   \n",
      "72    Ctrl1_GSM677181  5.707998  3.474379  3.024656  2.199321  11.358487   \n",
      "73    Ctrl1_GSM677182  5.730127   3.49068  3.024656  2.199321  11.129184   \n",
      "\n",
      "0  EXOC3-AS1      GSTK1    WDR83OS      DHDH  ...    ZNF185    ZNF184  \\\n",
      "2   2.774651  12.183542  10.955093  2.348419  ...  9.959245  7.749854   \n",
      "3   3.110821  12.025866  10.659271  2.208156  ...  9.423573  8.067625   \n",
      "4   2.776102  12.447559  10.718241  2.208156  ...  9.958122  7.754345   \n",
      "5   2.782354  12.432136  10.700025  2.208156  ...  9.729924  8.061314   \n",
      "6   2.983148  12.687848  10.735485  2.208156  ...  9.183146  8.125959   \n",
      "..       ...        ...        ...       ...  ...       ...       ...   \n",
      "69   3.40339  12.346988  10.624993  2.208156  ...  9.672606  8.627303   \n",
      "70  2.743372  12.277759  10.733188  2.303453  ...  9.137719  8.437916   \n",
      "71  2.979557  12.376565  10.571794  2.208156  ...  9.361117  8.583305   \n",
      "72  2.782354  12.235068  10.659511  2.208156  ...   9.68493  8.580955   \n",
      "73  2.782354  12.323944  10.670511  2.208156  ...  9.378953  7.812684   \n",
      "\n",
      "0        BAD      TRAT1    ZNF182    ZNF180      H3-4    PIK3IP1       BAX  \\\n",
      "2   6.816283  11.552857  7.490995  6.193858  2.755738  11.296513  8.099604   \n",
      "3   6.936443  11.123667  7.689091  6.558171  2.763142  11.399007  7.964222   \n",
      "4   6.944916   11.03672  7.377303  6.343656  2.763142  10.830696  8.586125   \n",
      "5   7.156412  11.405454  7.954635  6.553165  2.749619    11.4762  8.474714   \n",
      "6   7.295406  12.088892  8.073395  6.494811  2.763142  11.254364  8.619164   \n",
      "..       ...        ...       ...       ...       ...        ...       ...   \n",
      "69  6.938278  11.647541  8.225801  6.607068  2.763142  11.261386  7.750347   \n",
      "70  6.507245  11.754238  8.193679   6.54741  2.763142  11.648409  7.861734   \n",
      "71  6.602019  11.882352  8.469852  7.162839  2.755738  11.220264  8.323182   \n",
      "72  6.936443  11.281873  8.329305  6.550454  2.779304  10.781759  7.997715   \n",
      "73  6.852468  11.392206  8.244165  6.455245  2.763142  11.090666  8.467128   \n",
      "\n",
      "0       ABCE1  \n",
      "2   10.494201  \n",
      "3   10.313823  \n",
      "4     9.99545  \n",
      "5   10.264583  \n",
      "6   10.250189  \n",
      "..        ...  \n",
      "69  10.324018  \n",
      "70  10.245522  \n",
      "71  10.192351  \n",
      "72   9.802925  \n",
      "73   9.916428  \n",
      "\n",
      "[72 rows x 16903 columns]\n"
     ]
    }
   ],
   "source": [
    "X,y=prepare_dataset(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7684cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                NAME      HTR4      HTR6      HTR7        BBX EXOC3-AS1  \\\n",
      "2   Schizo1_GSM677118  5.727914   3.49068  3.680865  10.761437  2.774651   \n",
      "3   Schizo1_GSM677119  5.724901   3.49068  3.024656   10.63498  3.110821   \n",
      "4   Schizo1_GSM677120  6.239469   3.49068  3.505588  10.483729  2.776102   \n",
      "5   Schizo1_GSM677121  5.711125   3.48934  3.267655  10.919826  2.782354   \n",
      "6   Schizo1_GSM677122  5.100501  3.564864  3.024656  10.549424  2.983148   \n",
      "..                ...       ...       ...       ...        ...       ...   \n",
      "69    Ctrl1_GSM677178  5.681799   3.49068  3.024656  11.646984   3.40339   \n",
      "70    Ctrl1_GSM677179  5.730127   3.48934  3.024656  11.536132  2.743372   \n",
      "71    Ctrl1_GSM677180  5.681799   3.49068  3.024656   11.53018  2.979557   \n",
      "72    Ctrl1_GSM677181  5.707998  3.474379  3.024656  11.358487  2.782354   \n",
      "73    Ctrl1_GSM677182  5.730127   3.49068  3.024656  11.129184  2.782354   \n",
      "\n",
      "0      GSTK1      DHDH    INSYN1       BCR  ... C2orf49-DT      STN1  \\\n",
      "2   8.679802  2.348419  2.932074  8.237026  ...   3.355381  9.656106   \n",
      "3   8.650545  2.208156  2.932074  8.672393  ...   3.905272  9.439315   \n",
      "4   8.973636  2.208156  2.932074  8.675525  ...   3.796403  9.337188   \n",
      "5   9.131094  2.208156  2.932074  8.187227  ...   3.892843  9.384541   \n",
      "6    9.12073  2.208156  2.932074  8.402587  ...   3.152192  9.633257   \n",
      "..       ...       ...       ...       ...  ...        ...       ...   \n",
      "69  9.351986  2.208156  2.932074   8.78781  ...   3.191678  9.234821   \n",
      "70  9.143876  2.303453  2.932074  8.843235  ...    3.28462  9.265877   \n",
      "71  9.534994  2.208156  2.932074  8.795972  ...   4.085385   9.33596   \n",
      "72  9.243627  2.208156  3.300694  9.076212  ...   3.917351  9.290809   \n",
      "73  9.379497  2.208156  2.960779  8.537328  ...   3.152192  8.784542   \n",
      "\n",
      "0     ZNF185    ZNF184       BAD      TRAT1    ZNF182    ZNF180    PIK3IP1  \\\n",
      "2   9.959245  7.749854  6.816283  11.552857  7.490995  6.193858  11.296513   \n",
      "3   9.423573  8.067625  6.936443  11.123667  7.689091  6.558171  11.399007   \n",
      "4   9.958122  7.754345  6.944916   11.03672  7.377303  6.343656  10.830696   \n",
      "5   9.729924  8.061314  7.156412  11.405454  7.954635  6.553165    11.4762   \n",
      "6   9.183146  8.125959  7.295406  12.088892  8.073395  6.494811  11.254364   \n",
      "..       ...       ...       ...        ...       ...       ...        ...   \n",
      "69  9.672606  8.627303  6.938278  11.647541  8.225801  6.607068  11.261386   \n",
      "70  9.137719  8.437916  6.507245  11.754238  8.193679   6.54741  11.648409   \n",
      "71  9.361117  8.583305  6.602019  11.882352  8.469852  7.162839  11.220264   \n",
      "72   9.68493  8.580955  6.936443  11.281873  8.329305  6.550454  10.781759   \n",
      "73  9.378953  7.812684  6.852468  11.392206  8.244165  6.455245  11.090666   \n",
      "\n",
      "0        BAX  \n",
      "2   8.099604  \n",
      "3   7.964222  \n",
      "4   8.586125  \n",
      "5   8.474714  \n",
      "6   8.619164  \n",
      "..       ...  \n",
      "69  7.750347  \n",
      "70  7.861734  \n",
      "71  8.323182  \n",
      "72  7.997715  \n",
      "73  8.467128  \n",
      "\n",
      "[72 rows x 14284 columns]\n",
      "model_name xgb, feature_selection_method SelectKBest(k='all')\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k='all')),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.7983333333333335 +- 0.14370107863199913 std\n",
      "Accuracy 10 folds: 0.7946428571428571 +- 0.1038942014842061 std\n",
      "F1 10 folds: 0.777077922077922 +- 0.11900014270424794 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method SelectKBest(k=57)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=57)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.8 +- 0.1586400537905439 std\n",
      "Accuracy 10 folds: 0.725 +- 0.18214285714285716 std\n",
      "F1 10 folds: 0.7032142857142856 +- 0.21201913045290166 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method SelectKBest(k=72)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=72)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.8083333333333333 +- 0.15060064925343303 std\n",
      "Accuracy 10 folds: 0.7535714285714286 +- 0.17817813833237744 std\n",
      "F1 10 folds: 0.735595238095238 +- 0.20829554078982382 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None,...olicy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 10 folds: 0.8883333333333333 +- 0.1416274455511125 std\n",
      "Accuracy 10 folds: 0.8482142857142858 +- 0.09624652127294189 std\n",
      "F1 10 folds: 0.8378751803751804 +- 0.10667891943310347 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None,...olicy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.8883333333333333 +- 0.1416274455511125 std\n",
      "Accuracy 10 folds: 0.8482142857142858 +- 0.09624652127294189 std\n",
      "F1 10 folds: 0.8378751803751804 +- 0.10667891943310347 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.7700000000000001 +- 0.1810156530984728 std\n",
      "Accuracy 10 folds: 0.7410714285714285 +- 0.18817904251222112 std\n",
      "F1 10 folds: 0.7218253968253969 +- 0.21207887740026116 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.7616666666666667 +- 0.17560213868603966 std\n",
      "Accuracy 10 folds: 0.7517857142857143 +- 0.16798057771598454 std\n",
      "F1 10 folds: 0.7175324675324675 +- 0.20225267944537756 std\n",
      "__________________________________________________________________________\n",
      "model_name xgb, feature_selection_method PCA(n_components=15, random_state=42)\n",
      "Pipeline(steps=[('feature_selection', PCA(n_components=15, random_state=42)),\n",
      "                ('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               gamma=None, gpu_id=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_to_onehot=None,\n",
      "                               max_delta_step=None, max_depth=None,\n",
      "                               max_leaves=None, min_child_weight=None,\n",
      "                               missing=nan, monotone_constraints=None,\n",
      "                               n_estimators=100, n_jobs=None,\n",
      "                               num_parallel_tree=None, predictor=None,\n",
      "                               random_state=None, reg_alpha=None,\n",
      "                               reg_lambda=None, ...))])\n",
      "ROC AUC 10 folds: 0.8100000000000002 +- 0.17876116903722564 std\n",
      "Accuracy 10 folds: 0.8071428571428573 +- 0.10528144980702624 std\n",
      "F1 10 folds: 0.7791594516594517 +- 0.1260600746485193 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectKBest(k='all')\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k='all')), ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.8316666666666667 +- 0.15392097539538482 std\n",
      "Accuracy 10 folds: 0.7696428571428571 +- 0.1870232032968866 std\n",
      "F1 10 folds: 0.7575000000000001 +- 0.20073564395202578 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectKBest(k=57)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=57)), ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.8416666666666668 +- 0.15850867484147357 std\n",
      "Accuracy 10 folds: 0.7964285714285715 +- 0.1565329071486509 std\n",
      "F1 10 folds: 0.784484126984127 +- 0.1682686099124986 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectKBest(k=72)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=72)), ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.8450000000000001 +- 0.1262823115967641 std\n",
      "Accuracy 10 folds: 0.8214285714285715 +- 0.11978935593748873 std\n",
      "F1 10 folds: 0.7991017316017317 +- 0.14205974751150854 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model', SVC())])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 10 folds: 0.825 +- 0.15567951410224504 std\n",
      "Accuracy 10 folds: 0.6875 +- 0.21917778870411228 std\n",
      "F1 10 folds: 0.660609668109668 +- 0.2430033701644301 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.825 +- 0.15567951410224504 std\n",
      "Accuracy 10 folds: 0.6875 +- 0.21917778870411228 std\n",
      "F1 10 folds: 0.660609668109668 +- 0.2430033701644301 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.7166666666666666 +- 0.1648231375343482 std\n",
      "Accuracy 10 folds: 0.6678571428571428 +- 0.1417816660091372 std\n",
      "F1 10 folds: 0.6642857142857143 +- 0.1427987093897426 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.7166666666666666 +- 0.1648231375343482 std\n",
      "Accuracy 10 folds: 0.6553571428571427 +- 0.12778779044867747 std\n",
      "F1 10 folds: 0.6503174603174602 +- 0.12773522903927992 std\n",
      "__________________________________________________________________________\n",
      "model_name svm, feature_selection_method PCA(n_components=15, random_state=42)\n",
      "Pipeline(steps=[('feature_selection', PCA(n_components=15, random_state=42)),\n",
      "                ('model', SVC())])\n",
      "ROC AUC 10 folds: 0.8766666666666667 +- 0.14224392195567911 std\n",
      "Accuracy 10 folds: 0.85 +- 0.1819677028979571 std\n",
      "F1 10 folds: 0.8422619047619048 +- 0.19475495534231085 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectKBest(k='all')\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k='all')),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.8741666666666668 +- 0.12728194861976477 std\n",
      "Accuracy 10 folds: 0.8214285714285714 +- 0.12371791482634838 std\n",
      "F1 10 folds: 0.8048809523809524 +- 0.13738437383981864 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectKBest(k=57)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=57)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.8166666666666668 +- 0.12952906151816965 std\n",
      "Accuracy 10 folds: 0.7642857142857143 +- 0.15583874449479593 std\n",
      "F1 10 folds: 0.7336111111111111 +- 0.1886495624362999 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectKBest(k=72)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=72)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.8483333333333334 +- 0.1662411234054652 std\n",
      "Accuracy 10 folds: 0.7660714285714285 +- 0.1757727109603972 std\n",
      "F1 10 folds: 0.7439430014430014 +- 0.20610858712489613 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.8433333333333334 +- 0.16519348924485155 std\n",
      "Accuracy 10 folds: 0.7910714285714285 +- 0.14595961490656745 std\n",
      "F1 10 folds: 0.7593001443001441 +- 0.18741627580597595 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.8433333333333334 +- 0.16519348924485155 std\n",
      "Accuracy 10 folds: 0.7910714285714285 +- 0.14595961490656745 std\n",
      "F1 10 folds: 0.7593001443001441 +- 0.18741627580597595 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.7466666666666667 +- 0.18734993995195195 std\n",
      "Accuracy 10 folds: 0.7392857142857141 +- 0.14987239470255204 std\n",
      "F1 10 folds: 0.7143795093795093 +- 0.18141261197767303 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.7716666666666667 +- 0.16849826903166296 std\n",
      "Accuracy 10 folds: 0.7125 +- 0.14735118747054463 std\n",
      "F1 10 folds: 0.6789213564213564 +- 0.15102601425238624 std\n",
      "__________________________________________________________________________\n",
      "model_name rf, feature_selection_method PCA(n_components=15, random_state=42)\n",
      "Pipeline(steps=[('feature_selection', PCA(n_components=15, random_state=42)),\n",
      "                ('model', RandomForestClassifier())])\n",
      "ROC AUC 10 folds: 0.865 +- 0.17311685199438107 std\n",
      "Accuracy 10 folds: 0.7803571428571429 +- 0.14552201951342383 std\n",
      "F1 10 folds: 0.761031746031746 +- 0.18131341038124177 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectKBest(k='all')\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k='all')),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.8066666666666666 +- 0.1418528188730214 std\n",
      "Accuracy 10 folds: 0.7160714285714286 +- 0.23857169589377664 std\n",
      "F1 10 folds: 0.6946031746031747 +- 0.2620732502773985 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectKBest(k=57)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=57)),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.7733333333333333 +- 0.1793816539609828 std\n",
      "Accuracy 10 folds: 0.6589285714285713 +- 0.15900880799631245 std\n",
      "F1 10 folds: 0.6445238095238095 +- 0.16682841735292803 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectKBest(k=72)\n",
      "Pipeline(steps=[('feature_selection', SelectKBest(k=72)),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.7483333333333333 +- 0.18774243585887082 std\n",
      "Accuracy 10 folds: 0.6732142857142855 +- 0.18106297528873253 std\n",
      "F1 10 folds: 0.6575396825396826 +- 0.1877607366578133 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model', LogisticRegression())])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 10 folds: 0.735 +- 0.16149475395676344 std\n",
      "Accuracy 10 folds: 0.6839285714285713 +- 0.12927634141241617 std\n",
      "F1 10 folds: 0.6398304473304472 +- 0.1612696682945342 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                 random_state=42),\n",
      "                max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_estimators=8,\n",
      "                                                                  random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.735 +- 0.16149475395676344 std\n",
      "Accuracy 10 folds: 0.6839285714285713 +- 0.12927634141241617 std\n",
      "F1 10 folds: 0.6398304473304472 +- 0.1612696682945342 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=57)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=57)),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.7983333333333335 +- 0.19485749778862615 std\n",
      "Accuracy 10 folds: 0.7035714285714285 +- 0.22477312825085088 std\n",
      "F1 10 folds: 0.6927777777777777 +- 0.2372089854889022 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method SelectFromModel(estimator=LogisticRegression(random_state=42), max_features=72)\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
      "                                 max_features=72)),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.8066666666666666 +- 0.1943936441576444 std\n",
      "Accuracy 10 folds: 0.7035714285714285 +- 0.22477312825085088 std\n",
      "F1 10 folds: 0.6927777777777777 +- 0.2372089854889022 std\n",
      "__________________________________________________________________________\n",
      "model_name lr, feature_selection_method PCA(n_components=15, random_state=42)\n",
      "Pipeline(steps=[('feature_selection', PCA(n_components=15, random_state=42)),\n",
      "                ('model', LogisticRegression())])\n",
      "ROC AUC 10 folds: 0.7866666666666666 +- 0.1894143019356716 std\n",
      "Accuracy 10 folds: 0.7410714285714286 +- 0.17076695242586115 std\n",
      "F1 10 folds: 0.7265656565656566 +- 0.1738768794283117 std\n",
      "__________________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'get_support'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21872/3190896201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mprepare_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mbest_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest_f1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeats\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mresults_dict_f1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mbest_f1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mresults_dict_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mbest_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\autoNeuro\\experiments\\../core\\experiments.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(X, y, experiment_name, topN, repeats, scaling, targets_name)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExperimentsInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimportant_features_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_important_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\autoNeuro\\experiments\\../core\\metrics.py\u001b[0m in \u001b[0;36mget_important_features\u001b[1;34m(self, experiments_count)\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_most_common_entitis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_roc_auc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_auc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_most_common_entitis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mconfusions_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mA_precisions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"precision\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\autoNeuro\\experiments\\../core\\metrics.py\u001b[0m in \u001b[0;36mcalculate_most_common_entitis\u001b[1;34m(self, topN, show_roc_auc)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature_selection'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mfeatures_df_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'get_support'"
     ]
    }
   ],
   "source": [
    "results_dict_metrics ={}\n",
    "results_dict_f1 ={}\n",
    "for file in files[1:]:\n",
    "    X,y =prepare_dataset(file)\n",
    "    best_result,best_f1 =run(X,y, experiment_name=file.stem, repeats =10, topN=1,scaling=False)\n",
    "    results_dict_f1[file.stem] =best_f1\n",
    "    results_dict_metrics[file.stem] =best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f261a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
